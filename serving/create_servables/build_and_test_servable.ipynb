{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Test Servable\n",
    "\n",
    "This notebook takes a model that was saved in tf1 and converts it to a tf2 model that is servable and encapsulated in a Docker image. Tests are also run to ensure that nothing was messed up in the conversion process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development Environment\n",
    "\n",
    "Create a new conda environment with the latest versions of `tensorflow`, `numpy`, `cv2`, and `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test imports. \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "assert tf.__version__ == \"2.0.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Check of the Model\n",
    "\n",
    "Test out the model on a few images just to make sure it's creating reasonable predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "model = tf.saved_model.load(\"gender_model_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'data:0' shape=(1, 224, 224, 3) dtype=float32>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.signatures['serving_default'].inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': <tf.Tensor 'prob:0' shape=(1, 2) dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "infer = model.signatures[\"serving_default\"]\n",
    "print(infer.structured_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones([1, 224, 224, 3]).astype('float32')\n",
    "y = infer(tf.constant(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31617698, 0.68382293], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['output'].numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man1.jpeg\n",
      "[0.00256076 0.99743927]\n",
      "man2.jpeg\n",
      "[0.00449356 0.9955064 ]\n",
      "man3.jpeg\n",
      "[0.00320393 0.9967961 ]\n",
      "man4.jpeg\n",
      "[0.00619051 0.9938095 ]\n",
      "carl.jpg\n",
      "[0.00196772 0.9980323 ]\n",
      "woman1.jpg\n",
      "[0.9972639  0.00273612]\n",
      "woman2.jpeg\n",
      "[0.22375257 0.77624744]\n",
      "woman3.jpeg\n",
      "[0.9957283  0.00427165]\n",
      "woman4.jpeg\n",
      "[0.9678138  0.03218627]\n",
      "jiyoung.jpeg\n",
      "[0.99224126 0.00775879]\n"
     ]
    }
   ],
   "source": [
    "# Grab some pictures from the internet, turn them into tensors, and feed them to the model.\n",
    "# The predictions seem reasonable: it looks like class 1 is female and class 2 is male.\n",
    "for pic in [\"man1.jpeg\", \"man2.jpeg\", \"man3.jpeg\", \"man4.jpeg\", \"carl.jpg\",\n",
    "            \"woman1.jpg\", \"woman2.jpeg\", \"woman3.jpeg\", \"woman4.jpeg\",\n",
    "            \"jiyoung.jpeg\"]:\n",
    "\n",
    "    img = cv2.imread(pic)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = img.reshape(1, 224, 224, 3).astype('float32')\n",
    "    y = infer(tf.constant(img))\n",
    "    print(pic)\n",
    "    print(y['output'].numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./gender_model_serving_2/1/assets\n"
     ]
    }
   ],
   "source": [
    "# Save this as a new SavedModel\n",
    "# https://www.tensorflow.org/guide/saved_model\n",
    "\n",
    "# Make sure tp pass the serving signature!\n",
    "tf.saved_model.save(model, \"./gender_model_serving_2/1/\", signatures=model.signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_SignatureMap({})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ = tf.saved_model.load(\"./gender_model_serving_2/1/\")\n",
    "model_.signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_SignatureMap({'serving_default': <tensorflow.python.eager.wrap_function.WrappedFunction object at 0x654cb6790>})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\n",
      "SignatureDef key: \"__saved_model_init_op\"\n",
      "SignatureDef key: \"serving_default\"\n"
     ]
    }
   ],
   "source": [
    "! saved_model_cli show --dir ./gender_model_serving_2/1/ --tag_set serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to tf image\n",
    "\n",
    "Add this model to a tensorflow docker image. This can then be easily deployed online. These commands follow [this documentation](https://www.tensorflow.org/tfx/serving/docker)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cameron_screenshot.png\n",
      "[[0.02354481 0.97645515]]\n",
      "69.68039\n",
      "man1.jpeg\n",
      "[[0.00256077 0.99743927]]\n",
      "34.20193\n",
      "man2.jpeg\n",
      "[[0.00449357 0.99550641]]\n",
      "129.97061\n",
      "man3.jpeg\n",
      "[[0.00320393 0.99679607]]\n",
      "112.29698\n",
      "man4.jpeg\n",
      "[[0.00619052 0.99380952]]\n",
      "219.36722\n",
      "carl.jpg\n",
      "[[0.00196772 0.99803227]]\n",
      "124.49874\n",
      "woman1.jpg\n",
      "[[0.99726391 0.00273612]]\n",
      "74.30365\n",
      "woman2.jpeg\n",
      "[[0.2237528 0.7762472]]\n",
      "111.5687\n",
      "woman3.jpeg\n",
      "[[0.99572831 0.00427166]]\n",
      "89.461266\n",
      "woman4.jpeg\n",
      "[[0.96781367 0.03218631]]\n",
      "113.05363\n",
      "jiyoung.jpeg\n",
      "[[0.99224126 0.00775878]]\n",
      "108.43575\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy\n",
    "import requests\n",
    "import cv2\n",
    "\n",
    "url = \"localhost\"\n",
    "port = \"8080\"\n",
    "model = \"gender_model\"\n",
    "\n",
    "# Mimic the shape of the incoming data. First axis are number of images.\n",
    "\n",
    "for pic in [\"cameron_screenshot.png\", \"man1.jpeg\", \"man2.jpeg\", \"man3.jpeg\", \"man4.jpeg\", \"carl.jpg\",\n",
    "            \"woman1.jpg\", \"woman2.jpeg\", \"woman3.jpeg\", \"woman4.jpeg\",\n",
    "            \"jiyoung.jpeg\"]:\n",
    "\n",
    "    img = cv2.imread(\"data/\" + pic)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = img.reshape(1, 224, 224, 3).astype('float32')\n",
    "    print(pic)\n",
    "\n",
    "    data = json.dumps({\"signature_name\": \"serving_default\",\n",
    "                       \"instances\": img.tolist()})\n",
    "    headers = {\"content-type\": \"application/json\"}\n",
    "    json_response = requests.post(f\"http://{url}:{port}/v1/models/{model}:predict\", data=data, headers=headers)\n",
    "\n",
    "    predictions = numpy.array(json.loads(json_response.text)[\"predictions\"])\n",
    "\n",
    "    print(predictions) # predictions are the same to a several decimal places.\n",
    "    print(img.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run complete tests\n",
    "\n",
    "Test the converted model against the original, generating the same statistics as in the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"data/\" + pic)\n",
    "img = cv2.resize(img, (224, 224))\n",
    "# img = img.reshape(1, 224, 224, 3).astype('float32')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
